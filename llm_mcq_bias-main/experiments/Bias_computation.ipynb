{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers peft matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "torch.cuda.is_available()\n",
    "# !pip uninstall torch -y\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "# train_data = MyLLMDataloader(4, tokenizer, \"cleaned_TeleQnA_train_context_gte.json\", shuffle=True)\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from string import Template\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import time\n",
    "from statistics import mode\n",
    "from transformers import logging\n",
    "import os\n",
    "import yaml\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), '..')), \"config/main.yaml\")\n",
    "\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "config[\"DATASET_PATH\"] = config[\"PATHS\"][config[\"DATASET_ID\"]]\n",
    "\n",
    "MODEL_ID = config[\"MODEL_ID\"]\n",
    "DATASET_ID = config[\"DATASET_ID\"]\n",
    "DATASET_PATH = config[\"DATASET_PATH\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if  DATASET_ID == \"medmcqa\" and MODEL_ID in [\"Qwen/Qwen2.5-3B-Instruct\" ,\"microsoft/phi-2\", \"google-t5/t5-3b\"] :\n",
    "\n",
    "    prompt_without_contex_train= Template('''Instruct = Youre a Medical Question Answering Expert, answer the following question. Please generate only answer choice (1, 2, 3 or 4)\\n                                                                 \n",
    "    $question\n",
    "    $options\n",
    "    Output: option ''')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "elif DATASET_ID == \"teleqna\" and MODEL_ID in [\"Qwen/Qwen2.5-3B-Instruct\",\"google-t5/t5-3b\"]  :\n",
    "    \n",
    "    prompt_without_contex_train= Template('''Instruct: $question\n",
    "    Abbreviations: $abbreviation\n",
    "            \n",
    "    Considering the following contexts:\n",
    "    context 1: $context1\n",
    "    context 2: $context2\n",
    "    context 3: $context3      \n",
    "                                                                        \n",
    "    $question\n",
    "    $options\n",
    "    Output: option ''')\n",
    "\n",
    "elif DATASET_ID == \"teleqna\" and MODEL_ID == \"microsoft/phi-2\":\n",
    "\n",
    "\n",
    "    prompt_without_contex_train= Template('''Instruct: $question\n",
    "    Abbreviations: $abbreviation\n",
    "            \n",
    "    Considering the following contexts:\n",
    "    context 1: $context1\n",
    "    context 2: $context2\n",
    "    context 3: $context3      \n",
    "                                                                        \n",
    "    $question\n",
    "    $options\n",
    "    Output: option ''')\n",
    "\n",
    "elif DATASET_ID == \"qasc\" and MODEL_ID in [\"Qwen/Qwen2.5-3B-Instruct\",\"google-t5/t5-3b\" ,\"microsoft/phi-2\"]:\n",
    "\n",
    "    prompt_without_contex_train = Template('''Instruct: Answer the following question using the context provided, reason over it because only one of the context is relevant . Please generate only answer choice (1, 2, 3, 4, 5, 6, 7 or 8) without any explanations\\n\n",
    "    $question\n",
    "    context: $context      \n",
    "                                                            \n",
    "    $options\n",
    "    $question\n",
    "    Output: option \n",
    "    ''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_question(question):\n",
    "    for num in [14, 15, 16, 17, 18]:\n",
    "        question = question.replace(f\"[3GPP Release {num}]\", \"\")\n",
    "    return question\n",
    "\n",
    "with open('time_no_bqkv'+DATASET_ID+\"_\"+ MODEL_ID.split('/')[1]+'.txt', 'w') as the_file:\n",
    "    the_file.write('')\n",
    "\n",
    "    # Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff695ea3bae64a209583ff8b31b0489f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "# torch.set_default_device(\"cuda\")\n",
    "if MODEL_ID == \"google-t5/t5-3b\":\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_ID)\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"/home/ubuntu/data/telcom_llm/medmcqa/logs_bias/medmcqa_qwen/model\", trust_remote_code=True, device_map=\"auto\", cache_dir = \"/home/ubuntu/data/cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLMDataloader:\n",
    "    def __init__(self, batch_size, tokenizer, data, shuffle = False, val= False, k=20):\n",
    "        ## initializations\n",
    "        self.batch_size  = batch_size\n",
    "        self.tokenizer  = tokenizer\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        # with open(data, \"r\") as f:\n",
    "        #     self.data = json.load(f)\n",
    "        if DATASET_ID == \"medmcqa\" or DATASET_ID == \"qasc\":\n",
    "            self.data = []\n",
    "            with open(data, \"r\") as f:\n",
    "                test_data = f.readlines()\n",
    "\n",
    "            for line in test_data:\n",
    "                self.data.append(json.loads(line))\n",
    "        elif DATASET_ID == \"teleqna\" :\n",
    "            with open(data, \"r\") as f:\n",
    "                self.data = json.load(f)\n",
    "            self.all_examples = list(self.data.keys())\n",
    "\n",
    "            \n",
    "        # self.all_examples = list(self.data.keys())\n",
    "        self.shuffle = shuffle\n",
    "        self.val = val\n",
    "        self.k = k\n",
    "        self.n_data_points = math.ceil(len(self.data)/self.batch_size)\n",
    "        self.indices = [i for i in range(self.n_data_points)]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        ## this gets a batch \n",
    "\n",
    "        option_header = [\"option 1 \", \"option 2 \", \"option 3 \", \"option 4 \", \"option 5 \"]\n",
    "        batch_start_id = idx * self.batch_size\n",
    "        mapper_ans = {\"a\":1, \"b\":2, \"c\":3, \"d\":4, \"e\":5}\n",
    "        batch_end_id  = min(len(self.data), batch_start_id + self.batch_size) \n",
    "        batch = {\"question_context\":[], \"answer\":[]}\n",
    "\n",
    "        batch_type =False\n",
    "        \n",
    "        if DATASET_ID == \"medmcqa\":\n",
    "            for i in range(batch_start_id, batch_end_id):\n",
    "                example = self.data[i]\n",
    "                options = []\n",
    "                opts = []\n",
    "                for key in example.keys():\n",
    "                    if key.startswith(\"op\"):\n",
    "                        if example[key] == None:\n",
    "                            continue\n",
    "                        options.append(example[key])\n",
    "                        opts.append((example[key], mapper_ans[key.split(\"op\")[1]] ))\n",
    "\n",
    "        elif DATASET_ID == \"teleqna\":\n",
    "            for i in range(batch_start_id, batch_end_id):\n",
    "                example = self.data[self.all_examples[i]]\n",
    "                options = []\n",
    "                opts = []\n",
    "                for key in example.keys():\n",
    "                    if key.startswith(\"opt\"):\n",
    "                        if example[key] == None:\n",
    "                            continue\n",
    "                        options.append(example[key])\n",
    "                        opts.append((example[key], key.split(\"option \")[1]))\n",
    "            \n",
    "        elif DATASET_ID == \"qasc\":\n",
    "                mapper_ans = {\"A\":1, \"B\":2, \"C\":3, \"D\":4, \"E\":5, \"F\":6, \"G\":7, \"H\":8}\n",
    "                option_header = [\"option 1 \", \"option 2 \", \"option 3 \", \"option 4 \", \"option 5 \",\"option 6 \", \"option 7 \", \"option 8 \" ]\n",
    "\n",
    "                for i in range(batch_start_id, batch_end_id):\n",
    "                    example = self.data[i]\n",
    "                    options = []\n",
    "                    opts = []\n",
    "                    context = example[\"fact1\"] + '\\n' + example[\"fact2\"]\n",
    "                    for i, sample in enumerate(example['question']['choices']):\n",
    "                        # print(key)\n",
    "                        if example[\"answerKey\"] == sample[\"label\"]:\n",
    "                            correct_option_id = mapper_ans[example[\"answerKey\"]]\n",
    "                            correct_option_txt = sample[\"text\"]\n",
    "                        \n",
    "                            \n",
    "                    \n",
    "                        # options.append(option_header[i]+ sample['text'])\n",
    "                        options.append(sample['text'])\n",
    "\n",
    "                        opts.append((sample['text'], option_header[i].split(\"option\")[1]))\n",
    "                 \n",
    "                explanation = example['combinedfact']\n",
    "\n",
    "        string_opts = ' '.join(opt[0] for opt in opts)\n",
    "        batch_prompts = []\n",
    "        option_maps = []\n",
    "        if not (\"option\" in string_opts or \"above\" in string_opts) and self.k>1:\n",
    "                batch_type = True\n",
    "\n",
    "                all_permutations = list(itertools.permutations(opts))\n",
    "                all_permutations = random.sample(all_permutations, self.k if len(all_permutations)>self.k else len(all_permutations))\n",
    "                for option_set in all_permutations:\n",
    "                    option_map = []\n",
    "                    options_with_header   = []\n",
    "                    for z in range(len(option_set)):\n",
    "\n",
    "                        options_with_header.append(option_header[z] +option_set[z][0])\n",
    "\n",
    "                        \n",
    "                        option_map.append(int(option_set[z][1]))\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    # options_with_header = \"\\n\".join(options_with_header)\n",
    "                    if DATASET_ID == \"medmcqa\":                    \n",
    "                        options_with_header = \"\\n\".join(options_with_header)\n",
    "\n",
    "                        prompt = prompt_without_contex_train.substitute(question = clean_question(example[\"question\"]), options =options_with_header)\n",
    "                    \n",
    "                    elif DATASET_ID == \"teleqna\":\n",
    "                        options_with_header = \"\\n\".join(options_with_header)\n",
    "                        prompt = prompt_without_contex_train.substitute(question = clean_question(example[\"question\"]),\\\n",
    "                        abbreviation='\\n'.join(example[\"abbreviation\"]), context1 = '\\n'.join(example[\"context_qwen2\"][:2])[:512] , context2 = '\\n'.join(example[\"context_gle\"])[:512], context3 = '\\n'.join(example[\"context_bm\"][:2])[:512],\n",
    "                        options =options_with_header)     \n",
    "                    \n",
    "                    elif DATASET_ID == \"qasc\":\n",
    "\n",
    "                        options_with_header = \"\\n\".join(options_with_header)\n",
    "\n",
    "                        prompt = prompt_without_contex_train.substitute( question  = example['question']['stem'], context=  context, options = options_with_header)\n",
    "                    # print(question_context, prompt)\n",
    "                    batch_prompts.append(prompt)\n",
    "                    option_maps.append(option_map)\n",
    "                batch[\"question_context\"] += batch_prompts\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "        else:\n",
    "            if DATASET_ID == \"medmcqa\":\n",
    "            \n",
    "                options_with_header = [option_header[i] +options[i] for i in range(len(options)) ]\n",
    "            \n",
    "                options_with_header = \"\\n\".join(options_with_header)\n",
    "                prompt = prompt_without_contex_train.substitute(question = clean_question(example[\"question\"]), options =options_with_header)\n",
    "            elif DATASET_ID == \"teleqna\":\n",
    "                options_with_header = [option_header[i] +options[i] for i in range(len(options)) ]\n",
    "                options_with_header = \"\\n\".join(options_with_header)\n",
    "                prompt = prompt_without_contex_train.substitute(question = clean_question(example[\"question\"]),\\\n",
    "                abbreviation='\\n'.join(example[\"abbreviation\"]), context1 = '\\n'.join(example[\"context_qwen2\"][:2])[:512] , context2 = '\\n'.join(example[\"context_gle\"])[:512], context3 = '\\n'.join(example[\"context_bm\"][:2])[:512],\n",
    "                options =options_with_header)\n",
    "\n",
    "                # if MODEL_ID == \"google-t5/t5-3b\":\n",
    "                #     prompt = prompt_without_contex_train.substitute(question = clean_question(example[\"question\"]),\\\n",
    "                #     abbreviation='\\n'.join(example[\"abbreviation\"]), context1 = '\\n'.join(example[\"context_qwen2\"][:2])[:512] , context2 = '\\n'.join(example[\"context_gle\"])[:50], context3 = '\\n'.join(example[\"context_bm\"][:2])[:50],\n",
    "                #     options =options_with_header)     \n",
    "            \n",
    "            elif DATASET_ID == \"qasc\" :\n",
    "                correct_option_id = correct_option_id\n",
    "                correct_option_txt_header = str(correct_option_id) + \" \" + correct_option_txt\n",
    "                options_with_header = [option_header[i] +options[i] for i in range(len(options)) ]\n",
    "                options_with_header = \"\\n\".join(options_with_header)\n",
    "                prompt = prompt_without_contex_train.substitute( question  = example['question']['stem'], context=  context, options = options_with_header)\n",
    "\n",
    "                \n",
    "\n",
    "            batch_prompts.append(prompt)\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            batch[\"question_context\"] += batch_prompts\n",
    "            # batch[\"answer\"] += [answer]\n",
    "\n",
    "        self.tokenizer.padding_side = \"left\"\n",
    "        q_tokens = self.tokenizer(batch[\"question_context\"], padding=\"longest\", return_tensors=\"pt\")  \n",
    "        self.tokenizer.padding_side = \"right\"\n",
    "        # a_tokens = self.tokenizer(batch[\"answer\"], padding=\"longest\", return_tensors=\"pt\")\n",
    "        tokens = q_tokens\n",
    "        attn_masks = q_tokens[\"attention_mask\"]\n",
    "        \n",
    "       \n",
    "\n",
    "        # attn_masks = torch.cat([q_tokens[\"attention_mask\"], a_tokens[\"attention_mask\"]], dim=1)\n",
    "        # loss_mask = torch.cat([torch.zeros_like(q_tokens[\"attention_mask\"]), a_tokens[\"attention_mask\"]], dim=1)[:,1:]\n",
    "   \n",
    "        result = {\n",
    "        \"inp_ids\":tokens[\"input_ids\"],\n",
    "        \"inp_mask\":attn_masks,## Causal Training\n",
    "        \"option_maps\": option_maps\n",
    "        }\n",
    "\n",
    "        # result[\"loss_mask\"] = loss_mask * result[\"out_mask\"]\n",
    "        # result[\"out_ids\"][:,:q_tokens[\"input_ids\"].size(1)-10] = self.tokenizer.eos_token_id\n",
    "\n",
    "        return result       \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    def __iter__(self):\n",
    "        self.idx = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.idx >= self.n_data_points:\n",
    "            self.idx = 0\n",
    "            raise StopIteration\n",
    "        temp_idx = self.indices[self.idx]\n",
    "        self.idx += 1\n",
    "        return self[temp_idx]\n",
    "             \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data_points\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['inp_ids', 'inp_mask', 'option_maps'])\n"
     ]
    }
   ],
   "source": [
    "k=20\n",
    "testLoader = MyLLMDataloader(1, tokenizer, DATASET_PATH, val=True, shuffle=False, k=k)\n",
    "for doc in testLoader:\n",
    "    print(doc.keys())\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, batch):\n",
    "    inp_ids = batch[\"inp_ids\"].to(model.device)\n",
    "    attn_mask = batch[\"inp_mask\"].to(model.device)\n",
    "    decoder_input_ids = tokenizer([\"<pad>\"], return_tensors=\"pt\").input_ids\n",
    "\n",
    "    if MODEL_ID != \"google-t5/t5-3b\":\n",
    "\n",
    "        result = model(input_ids=inp_ids, attention_mask=attn_mask)\n",
    "        logits = result.logits\n",
    "        return logits\n",
    "    else:\n",
    "        result = model(\n",
    "            input_ids=inp_ids,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            output_attentions=True,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        logits = result.logits\n",
    "\n",
    "\n",
    "   \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_with_bias(model, testLoader):\n",
    "    \"\"\"\n",
    "    Perform inference on testLoader to compute biases in option permutations for LLMs.\n",
    "\n",
    "    Args:\n",
    "        model: The language model for inference.\n",
    "        testLoader: An iterable containing test data. Each item is expected to have\n",
    "                    the following keys:\n",
    "                    - \"inp_ids\": Input IDs for the model.\n",
    "                    - \"inp_mask\": Attention masks for the input IDs.\n",
    "                    - \"option_maps\": A tensor mapping permutations of options, where\n",
    "                      each row represents a specific permutation of option positions.\n",
    "                      For example:\n",
    "                      [[4, 1, 3, 2], [2, 1, 3, 4], [2, 4, 1, 3], ...]\n",
    "                      This structure is used to evaluate model biases by reordering\n",
    "                      the prediction probabilities to match these permutations.\n",
    "    Returns:\n",
    "        dict: A dictionary with \"Answer_ID\" and \"Bias\" for each example in testLoader.\n",
    "    \"\"\"\n",
    "   \n",
    "\n",
    "    # Initialize results dictionary\n",
    "    my_ans = {\"Answer_ID\": [], \"Bias\": []}\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    if DATASET_ID != \"qasc\":\n",
    "        option_ids = [tokenizer(o).input_ids[0] for o in [\"1\", \"2\", \"3\", \"4\", \"5\"]]\n",
    "    else:\n",
    "        option_ids = [tokenizer(o).input_ids[0] for o in [\"1\", \"2\", \"3\", \"4\", \"5\",\"6\", \"7\", \"8\"]]\n",
    "\n",
    "\n",
    "    pbar = tqdm(range(len(testLoader)), desc=\"Processing\")\n",
    "\n",
    "    for item in testLoader:\n",
    "        if len(item[\"option_maps\"]) > 0:\n",
    "            # Process items with option maps\n",
    "            with torch.inference_mode():\n",
    "                with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                    start = time.time()\n",
    "                    logits = forward_pass(model, item)\n",
    "                    # Log processing time\n",
    "                    with open(f'time_bqkv{DATASET_ID}_{MODEL_ID.split(\"/\")[1]}.txt', 'a') as the_file:\n",
    "                        the_file.write(f\"{time.time() - start}\\n\")\n",
    "\n",
    "            # Compute probabilities and adjust with option_maps\n",
    "            preds_probabs = torch.nn.functional.softmax(logits, dim=2)[:, -1, option_ids]\n",
    "            preds_probabs = preds_probabs/preds_probabs.sum(dim=1).unsqueeze(1)\n",
    "\n",
    "            z = torch.tensor(item[\"option_maps\"]).cpu()\n",
    "            reordered_probs = torch.gather(preds_probabs.cpu(), 1, torch.argsort(z, dim=1))\n",
    "\n",
    "            # Calculate bias as the variance across permutations\n",
    "            bias = torch.mean(torch.var(reordered_probs, dim=0))\n",
    "\n",
    "            # Resolve final prediction based on the reordered probabilities\n",
    "            preds = torch.mode(z.gather(1, preds_probabs.argmax(dim=1).cpu().unsqueeze(1)).squeeze(1)).values\n",
    "\n",
    "            # Save results\n",
    "            my_ans[\"Answer_ID\"].append(preds.item())\n",
    "            my_ans[\"Bias\"].append(bias.item())\n",
    "        else:\n",
    "            continue\n",
    "            # Handle cases without option maps\n",
    "            with torch.inference_mode():\n",
    "                with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                    logits = forward_pass(model, item)\n",
    "                preds = logits[:, -1, option_ids].argmax(dim=1) + 1\n",
    "                my_ans[\"Answer_ID\"].append(preds.item())\n",
    "                \n",
    "\n",
    "        # Save results to CSV and update progress bar\n",
    "        pd.DataFrame(my_ans).to_csv(\"law_ans.csv\", index=False)\n",
    "        pbar.set_description(f\"Prediction: {bias.item()}\")\n",
    "        pbar.update(1)\n",
    "\n",
    "    return my_ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc2ff01487b44eca8a0cc8357895d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/4183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 20\n",
    "testLoader = MyLLMDataloader(1, tokenizer, DATASET_PATH, val=True, shuffle=False, k=k)\n",
    "\n",
    "predictions = inference_with_bias(model, testLoader)\n",
    "\n",
    "pd.DataFrame(predictions).to_csv(DATASET_ID+\"_qwen3B_ans_k_\"+ str(k)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Bias is =  0.02959000940313199\n"
     ]
    }
   ],
   "source": [
    "# labels = pd.read_csv(\"/home/ubuntu/data/llm_mcq_bias-main/experiments/qasc_qwen3B_ans_k_20.csv\")\n",
    "# print(\"Accuracy is \", sum(labels[\"Answer_ID\"] == predictions[\"Answer_ID\"])/len(labels[\"Answer_ID\"] ))\n",
    "print(\"Average Bias is = \", sum(predictions[\"Bias\"])/len(predictions[\"Bias\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28msum\u001b[39m(\u001b[43mlabels\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m predictions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "sum(labels[\"Answer_ID\"] != predictions[\"Answer_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
